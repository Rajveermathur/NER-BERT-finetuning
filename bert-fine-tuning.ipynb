{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Template</th>\n",
       "      <th>Filled Template</th>\n",
       "      <th>Tokenised Filled Template</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In our video conference, discuss the role of e...</td>\n",
       "      <td>In our video conference, discuss the role of e...</td>\n",
       "      <td>['in', 'our', 'video', 'conference', ',', 'dis...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you draft a letter for [NAME_1] to send ...</td>\n",
       "      <td>Could you draft a letter for Dietrich, Schulis...</td>\n",
       "      <td>['could', 'you', 'draft', 'a', 'letter', 'for'...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-NAME', 'I-NA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discuss the options for [FULLNAME_1] who wants...</td>\n",
       "      <td>Discuss the options for Jeffery Pfeffer who wa...</td>\n",
       "      <td>['discuss', 'the', 'options', 'for', 'jeff', '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B-FULLNAME', 'I-FULLNAME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13. Write a press release announcing [FULLNAME...</td>\n",
       "      <td>13. Write a press release announcing Gayle Wat...</td>\n",
       "      <td>['13', '.', 'write', 'a', 'press', 'release', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FULLNAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9. Develop an inventory management plan for [F...</td>\n",
       "      <td>9. Develop an inventory management plan for Ev...</td>\n",
       "      <td>['9', '.', 'develop', 'an', 'inventory', 'mana...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Template  \\\n",
       "0  In our video conference, discuss the role of e...   \n",
       "1  Could you draft a letter for [NAME_1] to send ...   \n",
       "2  Discuss the options for [FULLNAME_1] who wants...   \n",
       "3  13. Write a press release announcing [FULLNAME...   \n",
       "4  9. Develop an inventory management plan for [F...   \n",
       "\n",
       "                                     Filled Template  \\\n",
       "0  In our video conference, discuss the role of e...   \n",
       "1  Could you draft a letter for Dietrich, Schulis...   \n",
       "2  Discuss the options for Jeffery Pfeffer who wa...   \n",
       "3  13. Write a press release announcing Gayle Wat...   \n",
       "4  9. Develop an inventory management plan for Ev...   \n",
       "\n",
       "                           Tokenised Filled Template  \\\n",
       "0  ['in', 'our', 'video', 'conference', ',', 'dis...   \n",
       "1  ['could', 'you', 'draft', 'a', 'letter', 'for'...   \n",
       "2  ['discuss', 'the', 'options', 'for', 'jeff', '...   \n",
       "3  ['13', '.', 'write', 'a', 'press', 'release', ...   \n",
       "4  ['9', '.', 'develop', 'an', 'inventory', 'mana...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'B-NAME', 'I-NA...  \n",
       "2  ['O', 'O', 'O', 'O', 'B-FULLNAME', 'I-FULLNAME...  \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FULLNAM...  \n",
       "4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FU...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Template</th>\n",
       "      <th>Filled Template</th>\n",
       "      <th>Tokenised Filled Template</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In our video conference, discuss the role of e...</td>\n",
       "      <td>In our video conference, discuss the role of e...</td>\n",
       "      <td>[in, our, video, conference, ,, discuss, the, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you draft a letter for [NAME_1] to send ...</td>\n",
       "      <td>Could you draft a letter for Dietrich, Schulis...</td>\n",
       "      <td>[could, you, draft, a, letter, for, dietrich, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-NAME, I-NAME, I-NAME, I-N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discuss the options for [FULLNAME_1] who wants...</td>\n",
       "      <td>Discuss the options for Jeffery Pfeffer who wa...</td>\n",
       "      <td>[discuss, the, options, for, jeff, ##ery, p, #...</td>\n",
       "      <td>[O, O, O, O, B-FULLNAME, I-FULLNAME, I-FULLNAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13. Write a press release announcing [FULLNAME...</td>\n",
       "      <td>13. Write a press release announcing Gayle Wat...</td>\n",
       "      <td>[13, ., write, a, press, release, announcing, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAME, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9. Develop an inventory management plan for [F...</td>\n",
       "      <td>9. Develop an inventory management plan for Ev...</td>\n",
       "      <td>[9, ., develop, an, inventory, management, pla...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Template  \\\n",
       "0  In our video conference, discuss the role of e...   \n",
       "1  Could you draft a letter for [NAME_1] to send ...   \n",
       "2  Discuss the options for [FULLNAME_1] who wants...   \n",
       "3  13. Write a press release announcing [FULLNAME...   \n",
       "4  9. Develop an inventory management plan for [F...   \n",
       "\n",
       "                                     Filled Template  \\\n",
       "0  In our video conference, discuss the role of e...   \n",
       "1  Could you draft a letter for Dietrich, Schulis...   \n",
       "2  Discuss the options for Jeffery Pfeffer who wa...   \n",
       "3  13. Write a press release announcing Gayle Wat...   \n",
       "4  9. Develop an inventory management plan for Ev...   \n",
       "\n",
       "                           Tokenised Filled Template  \\\n",
       "0  [in, our, video, conference, ,, discuss, the, ...   \n",
       "1  [could, you, draft, a, letter, for, dietrich, ...   \n",
       "2  [discuss, the, options, for, jeff, ##ery, p, #...   \n",
       "3  [13, ., write, a, press, release, announcing, ...   \n",
       "4  [9, ., develop, an, inventory, management, pla...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1  [O, O, O, O, O, O, B-NAME, I-NAME, I-NAME, I-N...  \n",
       "2  [O, O, O, O, B-FULLNAME, I-FULLNAME, I-FULLNAM...  \n",
       "3  [O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAME, ...  \n",
       "4  [O, O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAM...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_parse_list(cell):\n",
    "    if isinstance(cell, str):\n",
    "        return ast.literal_eval(cell)\n",
    "    return cell\n",
    "\n",
    "df[\"Tokenised Filled Template\"] = df[\"Tokenised Filled Template\"].apply(try_parse_list)\n",
    "df[\"Tokens\"] = df[\"Tokens\"].apply(try_parse_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch at index 701\n",
      "Mismatch at index 1123\n",
      "Mismatch at index 1906\n",
      "Mismatch at index 2141\n",
      "Mismatch at index 2192\n",
      "Mismatch at index 2205\n",
      "Mismatch at index 2375\n",
      "Mismatch at index 2387\n",
      "Mismatch at index 3218\n",
      "Mismatch at index 3381\n",
      "Mismatch at index 3654\n",
      "Mismatch at index 3870\n",
      "Mismatch at index 4265\n",
      "Mismatch at index 4993\n",
      "Mismatch at index 5071\n",
      "Mismatch at index 5135\n",
      "Mismatch at index 6312\n",
      "Mismatch at index 6801\n",
      "Mismatch at index 7190\n",
      "Mismatch at index 7384\n",
      "Mismatch at index 7779\n",
      "Mismatch at index 7843\n",
      "Mismatch at index 8652\n",
      "Mismatch at index 8710\n",
      "Mismatch at index 10344\n",
      "Mismatch at index 10800\n",
      "Mismatch at index 11358\n",
      "Mismatch at index 12127\n",
      "Mismatch at index 12358\n",
      "Mismatch at index 13103\n",
      "Mismatch at index 13467\n",
      "Mismatch at index 13574\n",
      "Mismatch at index 13642\n",
      "Mismatch at index 13709\n",
      "Mismatch at index 14074\n",
      "Mismatch at index 14272\n",
      "Mismatch at index 14604\n",
      "Mismatch at index 15549\n",
      "Mismatch at index 15775\n",
      "Mismatch at index 15847\n",
      "Mismatch at index 16239\n",
      "Mismatch at index 16297\n",
      "Mismatch at index 16604\n",
      "Mismatch at index 16872\n",
      "Mismatch at index 17013\n",
      "Mismatch at index 17252\n",
      "Mismatch at index 18583\n",
      "Mismatch at index 18718\n",
      "Mismatch at index 18959\n",
      "Mismatch at index 19461\n",
      "Mismatch at index 19527\n",
      "Mismatch at index 19644\n",
      "Mismatch at index 19842\n",
      "Mismatch at index 19939\n",
      "Mismatch at index 19975\n",
      "Mismatch at index 20893\n",
      "Mismatch at index 21988\n",
      "Mismatch at index 22152\n",
      "Mismatch at index 22562\n",
      "Mismatch at index 22606\n",
      "Mismatch at index 22670\n",
      "Total mismatches found: 61\n"
     ]
    }
   ],
   "source": [
    "# Check for mismatches between tokens and labels\n",
    "counter = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if len(row[\"Tokenised Filled Template\"]) != len(row[\"Tokens\"]):\n",
    "        print(f\"Mismatch at index {idx}\")\n",
    "        # print(f\"Tokens ({len(row['Tokenised Filled Template'])}): {row['Tokenised Filled Template']}\")\n",
    "        # print(f\"Labels ({len(row['Tokens'])}): {row['Tokens']}\")\n",
    "        counter += 1\n",
    "print(f\"Total mismatches found: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches found: 0\n"
     ]
    }
   ],
   "source": [
    "# Filter only rows where tokens and labels match in length\n",
    "df = df[df[\"Tokenised Filled Template\"].str.len() == df[\"Tokens\"].str.len()]\n",
    "# Check for mismatches between tokens and labels\n",
    "counter = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if len(row[\"Tokenised Filled Template\"]) != len(row[\"Tokens\"]):\n",
    "        print(f\"Mismatch at index {idx}\")\n",
    "        # print(f\"Tokens ({len(row['Tokenised Filled Template'])}): {row['Tokenised Filled Template']}\")\n",
    "        # print(f\"Labels ({len(row['Tokens'])}): {row['Tokens']}\")\n",
    "        counter += 1\n",
    "print(f\"Total mismatches found: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract BIO tag scheme\n",
    "all_tags = set(tag for tags in df[\"Tokens\"] for tag in tags)\n",
    "unique_tags = sorted(all_tags)\n",
    "label2id = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
    "id2label = {idx: tag for tag, idx in label2id.items()}\n",
    "\n",
    "# Add numeric label ids for each row\n",
    "df[\"Label_ids\"] = df[\"Tokens\"].apply(lambda tags: [label2id[tag] for tag in tags])\n",
    "\n",
    "# Train-validation split\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face datasets\n",
    "def to_hf_dataset(dataframe):\n",
    "    return Dataset.from_dict({\n",
    "        \"tokens\": dataframe[\"Tokenised Filled Template\"].tolist(),\n",
    "        \"labels\": dataframe[\"Label_ids\"].tolist()\n",
    "    })\n",
    "\n",
    "train_dataset = to_hf_dataset(train_df)\n",
    "val_dataset = to_hf_dataset(val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0803 00:33:54.709000 8620 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_checkpoint)\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(unique_tags),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20644/20644 [00:09<00:00, 2251.99 examples/s]\n",
      "Map: 100%|██████████| 2294/2294 [00:00<00:00, 2545.82 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",   # ensure uniform tensor sizes\n",
    "        max_length=128,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                # For subword tokens, assign -100 or the same label as the word\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(predictions_output):\n",
    "    preds, labels = predictions_output\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "\n",
    "    true_preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    for pred_seq, label_seq in zip(preds, labels):\n",
    "        pred_tags = []\n",
    "        label_tags = []\n",
    "        for p, l in zip(pred_seq, label_seq):\n",
    "            if l != -100:\n",
    "                pred_tags.append(id2label[p])\n",
    "                label_tags.append(id2label[l])\n",
    "        true_preds.append(pred_tags)\n",
    "        true_labels.append(label_tags)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, true_preds),\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\": recall_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds),\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner_output\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [12:28<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.72, 'grad_norm': 11.179600715637207, 'learning_rate': 1.9984502130956996e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [13:29<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6989, 'grad_norm': 2.8210830688476562, 'learning_rate': 1.9969004261913987e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [14:23<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3572, 'grad_norm': 1.9588127136230469, 'learning_rate': 1.9953506392870982e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [15:14<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3104, 'grad_norm': 3.284478187561035, 'learning_rate': 1.9938008523827976e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [15:59<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.089, 'grad_norm': 2.62977933883667, 'learning_rate': 1.9922510654784968e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [16:43<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1116, 'grad_norm': 2.5872581005096436, 'learning_rate': 1.9907012785741962e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [17:27<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9607, 'grad_norm': 4.221853256225586, 'learning_rate': 1.9891514916698957e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [18:10<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9951, 'grad_norm': 3.3762850761413574, 'learning_rate': 1.9876017047655948e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [18:54<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8704, 'grad_norm': 5.4681806564331055, 'learning_rate': 1.9860519178612942e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [19:39<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7217, 'grad_norm': 4.115973472595215, 'learning_rate': 1.9845021309569937e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [20:27<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9636, 'grad_norm': 4.363485336303711, 'learning_rate': 1.982952344052693e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [21:17<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7621, 'grad_norm': 4.1818461418151855, 'learning_rate': 1.9814025571483923e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [22:02<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7965, 'grad_norm': 3.9186975955963135, 'learning_rate': 1.9798527702440914e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [22:48<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.768, 'grad_norm': 5.949716567993164, 'learning_rate': 1.978302983339791e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [23:34<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5601, 'grad_norm': 4.571073055267334, 'learning_rate': 1.9767531964354903e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [24:21<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6731, 'grad_norm': 4.212614059448242, 'learning_rate': 1.9752034095311897e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [25:07<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6126, 'grad_norm': 5.589465141296387, 'learning_rate': 1.973653622626889e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [25:52<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5653, 'grad_norm': 3.776608467102051, 'learning_rate': 1.9721038357225883e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [26:35<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5811, 'grad_norm': 5.632179260253906, 'learning_rate': 1.9705540488182878e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [27:17<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.617, 'grad_norm': 3.2452123165130615, 'learning_rate': 1.9690042619139872e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [27:59<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5618, 'grad_norm': 4.0429863929748535, 'learning_rate': 1.9674544750096863e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [28:40<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7242, 'grad_norm': 4.446898937225342, 'learning_rate': 1.9659046881053855e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [29:24<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6973, 'grad_norm': 5.454800605773926, 'learning_rate': 1.964354901201085e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [30:07<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5156, 'grad_norm': 5.991216659545898, 'learning_rate': 1.9628051142967844e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [30:48<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5381, 'grad_norm': 3.29061222076416, 'learning_rate': 1.9612553273924838e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [31:28<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5279, 'grad_norm': 6.720741271972656, 'learning_rate': 1.959705540488183e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [32:10<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4426, 'grad_norm': 3.7190933227539062, 'learning_rate': 1.9581557535838824e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/12905 [32:52<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5278, 'grad_norm': 12.9356107711792, 'learning_rate': 1.956605966679582e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m trainer = Trainer(\n\u001b[32m      2\u001b[39m     model=model,\n\u001b[32m      3\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     compute_metrics=compute_metrics,\n\u001b[32m      8\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\transformers\\trainer.py:1624\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   1622\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2017\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2014\u001b[39m         grad_norm = _grad_norm.item() \u001b[38;5;28;01mif\u001b[39;00m _grad_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2016\u001b[39m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2017\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2018\u001b[39m optimizer_was_run = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.optimizer_step_was_skipped\n\u001b[32m   2019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[32m   2020\u001b[39m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\accelerate\\optimizer.py:145\u001b[39m, in \u001b[36mAcceleratedOptimizer.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m._accelerate_step_called = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:124\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m opt = opt_ref()\n\u001b[32m    123\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:525\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    523\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m         denom = (\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m / bias_correction2_sqrt).add_(eps)\n\u001b[32m    527\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    529\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./final_ner_model\")\n",
    "tokenizer.save_pretrained(\"./final_ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipeline = pipeline(\"ner\", model=\"./final_ner_model\", tokenizer=\"./final_ner_model\", aggregation_strategy=\"simple\")\n",
    "\n",
    "text = \"Dr. Marvin Rolfson and Julius Daugherty attended the arbitration.\"\n",
    "print(ner_pipeline(text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
