{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Template</th>\n",
       "      <th>Filled Template</th>\n",
       "      <th>Tokenised Filled Template</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In our video conference, discuss the role of e...</td>\n",
       "      <td>In our video conference, discuss the role of e...</td>\n",
       "      <td>['in', 'our', 'video', 'conference', ',', 'dis...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you draft a letter for [NAME_1] to send ...</td>\n",
       "      <td>Could you draft a letter for Dietrich, Schulis...</td>\n",
       "      <td>['could', 'you', 'draft', 'a', 'letter', 'for'...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-NAME', 'I-NA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discuss the options for [FULLNAME_1] who wants...</td>\n",
       "      <td>Discuss the options for Jeffery Pfeffer who wa...</td>\n",
       "      <td>['discuss', 'the', 'options', 'for', 'jeff', '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B-FULLNAME', 'I-FULLNAME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13. Write a press release announcing [FULLNAME...</td>\n",
       "      <td>13. Write a press release announcing Gayle Wat...</td>\n",
       "      <td>['13', '.', 'write', 'a', 'press', 'release', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FULLNAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9. Develop an inventory management plan for [F...</td>\n",
       "      <td>9. Develop an inventory management plan for Ev...</td>\n",
       "      <td>['9', '.', 'develop', 'an', 'inventory', 'mana...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Template  \\\n",
       "0  In our video conference, discuss the role of e...   \n",
       "1  Could you draft a letter for [NAME_1] to send ...   \n",
       "2  Discuss the options for [FULLNAME_1] who wants...   \n",
       "3  13. Write a press release announcing [FULLNAME...   \n",
       "4  9. Develop an inventory management plan for [F...   \n",
       "\n",
       "                                     Filled Template  \\\n",
       "0  In our video conference, discuss the role of e...   \n",
       "1  Could you draft a letter for Dietrich, Schulis...   \n",
       "2  Discuss the options for Jeffery Pfeffer who wa...   \n",
       "3  13. Write a press release announcing Gayle Wat...   \n",
       "4  9. Develop an inventory management plan for Ev...   \n",
       "\n",
       "                           Tokenised Filled Template  \\\n",
       "0  ['in', 'our', 'video', 'conference', ',', 'dis...   \n",
       "1  ['could', 'you', 'draft', 'a', 'letter', 'for'...   \n",
       "2  ['discuss', 'the', 'options', 'for', 'jeff', '...   \n",
       "3  ['13', '.', 'write', 'a', 'press', 'release', ...   \n",
       "4  ['9', '.', 'develop', 'an', 'inventory', 'mana...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'B-NAME', 'I-NA...  \n",
       "2  ['O', 'O', 'O', 'O', 'B-FULLNAME', 'I-FULLNAME...  \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FULLNAM...  \n",
       "4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FU...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries Import\n",
    "import pandas as pd\n",
    "import ast\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Template</th>\n",
       "      <th>Filled Template</th>\n",
       "      <th>Tokenised Filled Template</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In our video conference, discuss the role of e...</td>\n",
       "      <td>In our video conference, discuss the role of e...</td>\n",
       "      <td>[in, our, video, conference, ,, discuss, the, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you draft a letter for [NAME_1] to send ...</td>\n",
       "      <td>Could you draft a letter for Dietrich, Schulis...</td>\n",
       "      <td>[could, you, draft, a, letter, for, dietrich, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-NAME, I-NAME, I-NAME, I-N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discuss the options for [FULLNAME_1] who wants...</td>\n",
       "      <td>Discuss the options for Jeffery Pfeffer who wa...</td>\n",
       "      <td>[discuss, the, options, for, jeff, ##ery, p, #...</td>\n",
       "      <td>[O, O, O, O, B-FULLNAME, I-FULLNAME, I-FULLNAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13. Write a press release announcing [FULLNAME...</td>\n",
       "      <td>13. Write a press release announcing Gayle Wat...</td>\n",
       "      <td>[13, ., write, a, press, release, announcing, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAME, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9. Develop an inventory management plan for [F...</td>\n",
       "      <td>9. Develop an inventory management plan for Ev...</td>\n",
       "      <td>[9, ., develop, an, inventory, management, pla...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Template  \\\n",
       "0  In our video conference, discuss the role of e...   \n",
       "1  Could you draft a letter for [NAME_1] to send ...   \n",
       "2  Discuss the options for [FULLNAME_1] who wants...   \n",
       "3  13. Write a press release announcing [FULLNAME...   \n",
       "4  9. Develop an inventory management plan for [F...   \n",
       "\n",
       "                                     Filled Template  \\\n",
       "0  In our video conference, discuss the role of e...   \n",
       "1  Could you draft a letter for Dietrich, Schulis...   \n",
       "2  Discuss the options for Jeffery Pfeffer who wa...   \n",
       "3  13. Write a press release announcing Gayle Wat...   \n",
       "4  9. Develop an inventory management plan for Ev...   \n",
       "\n",
       "                           Tokenised Filled Template  \\\n",
       "0  [in, our, video, conference, ,, discuss, the, ...   \n",
       "1  [could, you, draft, a, letter, for, dietrich, ...   \n",
       "2  [discuss, the, options, for, jeff, ##ery, p, #...   \n",
       "3  [13, ., write, a, press, release, announcing, ...   \n",
       "4  [9, ., develop, an, inventory, management, pla...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1  [O, O, O, O, O, O, B-NAME, I-NAME, I-NAME, I-N...  \n",
       "2  [O, O, O, O, B-FULLNAME, I-FULLNAME, I-FULLNAM...  \n",
       "3  [O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAME, ...  \n",
       "4  [O, O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAM...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to convert string representation of lists into actual lists\n",
    "def try_parse_list(cell):\n",
    "    if isinstance(cell, str):\n",
    "        return ast.literal_eval(cell)\n",
    "    return cell\n",
    "\n",
    "# This is necessary if the columns contain lists stored as strings\n",
    "df[\"Tokenised Filled Template\"] = df[\"Tokenised Filled Template\"].apply(try_parse_list)\n",
    "df[\"Tokens\"] = df[\"Tokens\"].apply(try_parse_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Maximum number of tokens in any row: 127\n"
     ]
    }
   ],
   "source": [
    "# Maximum number of tokens in any row\n",
    "max_len = df[\"Tokenised Filled Template\"].apply(len).max()\n",
    "print(f\"🔢 Maximum number of tokens in any row: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch at index 701\n",
      "Mismatch at index 1123\n",
      "Mismatch at index 1906\n",
      "Mismatch at index 2141\n",
      "Mismatch at index 2192\n",
      "Mismatch at index 2205\n",
      "Mismatch at index 2375\n",
      "Mismatch at index 2387\n",
      "Mismatch at index 3218\n",
      "Mismatch at index 3381\n",
      "Mismatch at index 3654\n",
      "Mismatch at index 3870\n",
      "Mismatch at index 4265\n",
      "Mismatch at index 4993\n",
      "Mismatch at index 5071\n",
      "Mismatch at index 5135\n",
      "Mismatch at index 6312\n",
      "Mismatch at index 6801\n",
      "Mismatch at index 7190\n",
      "Mismatch at index 7384\n",
      "Mismatch at index 7779\n",
      "Mismatch at index 7843\n",
      "Mismatch at index 8652\n",
      "Mismatch at index 8710\n",
      "Mismatch at index 10344\n",
      "Mismatch at index 10800\n",
      "Mismatch at index 11358\n",
      "Mismatch at index 12127\n",
      "Mismatch at index 12358\n",
      "Mismatch at index 13103\n",
      "Mismatch at index 13467\n",
      "Mismatch at index 13574\n",
      "Mismatch at index 13642\n",
      "Mismatch at index 13709\n",
      "Mismatch at index 14074\n",
      "Mismatch at index 14272\n",
      "Mismatch at index 14604\n",
      "Mismatch at index 15549\n",
      "Mismatch at index 15775\n",
      "Mismatch at index 15847\n",
      "Mismatch at index 16239\n",
      "Mismatch at index 16297\n",
      "Mismatch at index 16604\n",
      "Mismatch at index 16872\n",
      "Mismatch at index 17013\n",
      "Mismatch at index 17252\n",
      "Mismatch at index 18583\n",
      "Mismatch at index 18718\n",
      "Mismatch at index 18959\n",
      "Mismatch at index 19461\n",
      "Mismatch at index 19527\n",
      "Mismatch at index 19644\n",
      "Mismatch at index 19842\n",
      "Mismatch at index 19939\n",
      "Mismatch at index 19975\n",
      "Mismatch at index 20893\n",
      "Mismatch at index 21988\n",
      "Mismatch at index 22152\n",
      "Mismatch at index 22562\n",
      "Mismatch at index 22606\n",
      "Mismatch at index 22670\n",
      "Total mismatches found: 61\n"
     ]
    }
   ],
   "source": [
    "# Check for mismatches between tokens length and labels length\n",
    "# This is to ensure that the tokenized filled template and tokens have the same length\n",
    "counter = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if len(row[\"Tokenised Filled Template\"]) != len(row[\"Tokens\"]):\n",
    "        print(f\"Mismatch at index {idx}\")\n",
    "        # print(f\"Tokens ({len(row['Tokenised Filled Template'])}): {row['Tokenised Filled Template']}\")\n",
    "        # print(f\"Labels ({len(row['Tokens'])}): {row['Tokens']}\")\n",
    "        counter += 1\n",
    "print(f\"Total mismatches found: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches found: 0\n"
     ]
    }
   ],
   "source": [
    "# Filter only rows where tokens and labels match in length\n",
    "df = df[df[\"Tokenised Filled Template\"].str.len() == df[\"Tokens\"].str.len()]\n",
    "\n",
    "\n",
    "# Check for mismatches between tokens and labels\n",
    "counter = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if len(row[\"Tokenised Filled Template\"]) != len(row[\"Tokens\"]):\n",
    "        print(f\"Mismatch at index {idx}\")\n",
    "        # print(f\"Tokens ({len(row['Tokenised Filled Template'])}): {row['Tokenised Filled Template']}\")\n",
    "        # print(f\"Labels ({len(row['Tokens'])}): {row['Tokens']}\")\n",
    "        counter += 1\n",
    "print(f\"Total mismatches found: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID to label mapping:\n",
      "0: B-ACCOUNTNAME\n",
      "1: B-ACCOUNTNUMBER\n",
      "2: B-AMOUNT\n",
      "3: B-BIC\n",
      "4: B-BITCOINADDRESS\n",
      "5: B-BUILDINGNUMBER\n",
      "6: B-CITY\n",
      "7: B-COUNTY\n",
      "8: B-CREDITCARDCVV\n",
      "9: B-CREDITCARDISSUER\n",
      "10: B-CREDITCARDNUMBER\n",
      "11: B-CURRENCY\n",
      "12: B-CURRENCYCODE\n",
      "13: B-CURRENCYNAME\n",
      "14: B-CURRENCYSYMBOL\n",
      "15: B-DISPLAYNAME\n",
      "16: B-EMAIL\n",
      "17: B-ETHEREUMADDRESS\n",
      "18: B-FIRSTNAME\n",
      "19: B-FULLNAME\n",
      "20: B-GENDER\n",
      "21: B-IBAN\n",
      "22: B-IP\n",
      "23: B-IPV4\n",
      "24: B-IPV6\n",
      "25: B-JOBAREA\n",
      "26: B-JOBDESCRIPTOR\n",
      "27: B-JOBTITLE\n",
      "28: B-JOBTYPE\n",
      "29: B-LASTNAME\n",
      "30: B-LITECOINADDRESS\n",
      "31: B-MAC\n",
      "32: B-MASKEDNUMBER\n",
      "33: B-NAME\n",
      "34: B-NEARBYGPSCOORDINATE\n",
      "35: B-NUMBER\n",
      "36: B-ORDINALDIRECTION\n",
      "37: B-PASSWORD\n",
      "38: B-PIN\n",
      "39: B-SECONDARYADDRESS\n",
      "40: B-SEX\n",
      "41: B-SEXTYPE\n",
      "42: B-STATE\n",
      "43: B-STREET\n",
      "44: B-STREETADDRESS\n",
      "45: B-URL\n",
      "46: B-USERAGENT\n",
      "47: B-USERNAME\n",
      "48: B-ZIPCODE\n",
      "49: I-ACCOUNTNAME\n",
      "50: I-ACCOUNTNUMBER\n",
      "51: I-AMOUNT\n",
      "52: I-BIC\n",
      "53: I-BITCOINADDRESS\n",
      "54: I-BUILDINGNUMBER\n",
      "55: I-CITY\n",
      "56: I-CREDITCARDCVV\n",
      "57: I-CREDITCARDISSUER\n",
      "58: I-CREDITCARDNUMBER\n",
      "59: I-CURRENCY\n",
      "60: I-CURRENCYCODE\n",
      "61: I-CURRENCYNAME\n",
      "62: I-DISPLAYNAME\n",
      "63: I-EMAIL\n",
      "64: I-ETHEREUMADDRESS\n",
      "65: I-FIRSTNAME\n",
      "66: I-FULLNAME\n",
      "67: I-GENDER\n",
      "68: I-IBAN\n",
      "69: I-IP\n",
      "70: I-IPV4\n",
      "71: I-IPV6\n",
      "72: I-JOBAREA\n",
      "73: I-JOBTITLE\n",
      "74: I-JOBTYPE\n",
      "75: I-LASTNAME\n",
      "76: I-LITECOINADDRESS\n",
      "77: I-MAC\n",
      "78: I-MASKEDNUMBER\n",
      "79: I-NAME\n",
      "80: I-NEARBYGPSCOORDINATE\n",
      "81: I-NUMBER\n",
      "82: I-PASSWORD\n",
      "83: I-PIN\n",
      "84: I-SECONDARYADDRESS\n",
      "85: I-STATE\n",
      "86: I-STREET\n",
      "87: I-STREETADDRESS\n",
      "88: I-URL\n",
      "89: I-USERAGENT\n",
      "90: I-USERNAME\n",
      "91: I-ZIPCODE\n",
      "92: O\n"
     ]
    }
   ],
   "source": [
    "# Extract BIO tag scheme\n",
    "all_tags = set(tag for tags in df[\"Tokens\"] for tag in tags)\n",
    "unique_tags = sorted(all_tags)\n",
    "\n",
    "label2id = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
    "# print(\"Unique tags and their IDs:\")\n",
    "# for tag, idx in label2id.items():\n",
    "#     print(f\"{tag}: {idx}\")\n",
    "\n",
    "# Create a mapping from ID to label\n",
    "id2label = {idx: tag for tag, idx in label2id.items()}\n",
    "print(\"\\nID to label mapping:\")\n",
    "for idx, tag in id2label.items():\n",
    "    print(f\"{idx}: {tag}\")\n",
    "\n",
    "# Add numeric label ids for each row\n",
    "df[\"Label_ids\"] = df[\"Tokens\"].apply(lambda tags: [label2id[tag] for tag in tags])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (20644, 5)\n",
      "Validation set size: (2294, 5)\n"
     ]
    }
   ],
   "source": [
    "# Train-validation split\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "print(f\"Training set size: {train_df.shape}\")\n",
    "print(f\"Validation set size: {val_df.shape}\")\n",
    "# Convert to Hugging Face datasets\n",
    "def to_hf_dataset(dataframe):\n",
    "    return Dataset.from_dict({\n",
    "        \"tokens\": dataframe[\"Tokenised Filled Template\"].tolist(),\n",
    "        \"labels\": dataframe[\"Label_ids\"].tolist()\n",
    "    })\n",
    "\n",
    "train_dataset = to_hf_dataset(train_df)\n",
    "val_dataset = to_hf_dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Template</th>\n",
       "      <th>Filled Template</th>\n",
       "      <th>Tokenised Filled Template</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Label_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In our video conference, discuss the role of e...</td>\n",
       "      <td>In our video conference, discuss the role of e...</td>\n",
       "      <td>[in, our, video, conference, ,, discuss, the, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you draft a letter for [NAME_1] to send ...</td>\n",
       "      <td>Could you draft a letter for Dietrich, Schulis...</td>\n",
       "      <td>[could, you, draft, a, letter, for, dietrich, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-NAME, I-NAME, I-NAME, I-N...</td>\n",
       "      <td>[92, 92, 92, 92, 92, 92, 33, 79, 79, 79, 79, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discuss the options for [FULLNAME_1] who wants...</td>\n",
       "      <td>Discuss the options for Jeffery Pfeffer who wa...</td>\n",
       "      <td>[discuss, the, options, for, jeff, ##ery, p, #...</td>\n",
       "      <td>[O, O, O, O, B-FULLNAME, I-FULLNAME, I-FULLNAM...</td>\n",
       "      <td>[92, 92, 92, 92, 19, 66, 66, 66, 66, 92, 92, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13. Write a press release announcing [FULLNAME...</td>\n",
       "      <td>13. Write a press release announcing Gayle Wat...</td>\n",
       "      <td>[13, ., write, a, press, release, announcing, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAME, ...</td>\n",
       "      <td>[92, 92, 92, 92, 92, 92, 92, 19, 66, 66, 92, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9. Develop an inventory management plan for [F...</td>\n",
       "      <td>9. Develop an inventory management plan for Ev...</td>\n",
       "      <td>[9, ., develop, an, inventory, management, pla...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAM...</td>\n",
       "      <td>[92, 92, 92, 92, 92, 92, 92, 92, 19, 66, 92, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Template  \\\n",
       "0  In our video conference, discuss the role of e...   \n",
       "1  Could you draft a letter for [NAME_1] to send ...   \n",
       "2  Discuss the options for [FULLNAME_1] who wants...   \n",
       "3  13. Write a press release announcing [FULLNAME...   \n",
       "4  9. Develop an inventory management plan for [F...   \n",
       "\n",
       "                                     Filled Template  \\\n",
       "0  In our video conference, discuss the role of e...   \n",
       "1  Could you draft a letter for Dietrich, Schulis...   \n",
       "2  Discuss the options for Jeffery Pfeffer who wa...   \n",
       "3  13. Write a press release announcing Gayle Wat...   \n",
       "4  9. Develop an inventory management plan for Ev...   \n",
       "\n",
       "                           Tokenised Filled Template  \\\n",
       "0  [in, our, video, conference, ,, discuss, the, ...   \n",
       "1  [could, you, draft, a, letter, for, dietrich, ...   \n",
       "2  [discuss, the, options, for, jeff, ##ery, p, #...   \n",
       "3  [13, ., write, a, press, release, announcing, ...   \n",
       "4  [9, ., develop, an, inventory, management, pla...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, O, O, B-NAME, I-NAME, I-NAME, I-N...   \n",
       "2  [O, O, O, O, B-FULLNAME, I-FULLNAME, I-FULLNAM...   \n",
       "3  [O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAME, ...   \n",
       "4  [O, O, O, O, O, O, O, O, B-FULLNAME, I-FULLNAM...   \n",
       "\n",
       "                                           Label_ids  \n",
       "0  [92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 9...  \n",
       "1  [92, 92, 92, 92, 92, 92, 33, 79, 79, 79, 79, 7...  \n",
       "2  [92, 92, 92, 92, 19, 66, 66, 66, 66, 92, 92, 9...  \n",
       "3  [92, 92, 92, 92, 92, 92, 92, 19, 66, 66, 92, 9...  \n",
       "4  [92, 92, 92, 92, 92, 92, 92, 92, 19, 66, 92, 9...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  # Display the first few rows of the DataFrame to verify changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Label Encoding\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",   # ensure uniform tensor sizes\n",
    "        max_length=128,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                # For subword tokens, assign -100 or the same label as the word\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0803 14:51:42.550000 18780 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 20644/20644 [00:04<00:00, 4610.87 examples/s]\n",
      "Map: 100%|██████████| 2294/2294 [00:00<00:00, 5212.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "\n",
    "model_checkpoint = \"prajjwal1/bert-tiny\"\n",
    "# model_checkpoint = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_checkpoint)\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(unique_tags),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer and Training Arguments\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(predictions_output):\n",
    "    preds, labels = predictions_output\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "\n",
    "    true_preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    for pred_seq, label_seq in zip(preds, labels):\n",
    "        pred_tags = []\n",
    "        label_tags = []\n",
    "        for p, l in zip(pred_seq, label_seq):\n",
    "            if l != -100:\n",
    "                pred_tags.append(id2label[p])\n",
    "                label_tags.append(id2label[l])\n",
    "        true_preds.append(pred_tags)\n",
    "        true_labels.append(label_tags)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, true_preds),\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\": recall_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds),\n",
    "    }\n",
    "\n",
    "# Training Argument\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner_output\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25810 [00:00<?, ?it/s]c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "  2%|▏         | 501/25810 [00:44<36:18, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3922, 'grad_norm': 3.694591760635376, 'learning_rate': 1.9612553273924838e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1001/25810 [01:31<36:03, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.116, 'grad_norm': 1.670870304107666, 'learning_rate': 1.922510654784967e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1501/25810 [02:18<39:54, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7546, 'grad_norm': 1.3517329692840576, 'learning_rate': 1.8837659821774508e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2001/25810 [03:01<34:26, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6183, 'grad_norm': 1.772323727607727, 'learning_rate': 1.845021309569934e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2501/25810 [03:44<33:02, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5289, 'grad_norm': 1.8229690790176392, 'learning_rate': 1.8062766369624178e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 10%|█         | 2581/25810 [03:58<32:10, 12.03it/s]c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4335784614086151, 'eval_accuracy': 0.9034560605557584, 'eval_precision': 0.33130252100840335, 'eval_recall': 0.4577648766328012, 'eval_f1': 0.3843997562461914, 'eval_runtime': 6.7605, 'eval_samples_per_second': 339.323, 'eval_steps_per_second': 42.452, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3001/25810 [04:34<33:29, 11.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4682, 'grad_norm': 4.563076972961426, 'learning_rate': 1.7675319643549015e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 3501/25810 [05:18<34:42, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4256, 'grad_norm': 3.139315605163574, 'learning_rate': 1.7287872917473848e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4002/25810 [06:03<29:49, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4, 'grad_norm': 1.0880024433135986, 'learning_rate': 1.6900426191398685e-05, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4502/25810 [06:46<31:34, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3687, 'grad_norm': 2.9844460487365723, 'learning_rate': 1.651297946532352e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5002/25810 [07:28<28:50, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3483, 'grad_norm': 1.4899905920028687, 'learning_rate': 1.6125532739248355e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 20%|██        | 5162/25810 [07:48<27:00, 12.74it/s]c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2825126349925995, 'eval_accuracy': 0.9381992629726769, 'eval_precision': 0.5085821772866213, 'eval_recall': 0.6278664731494921, 'eval_f1': 0.5619641465315667, 'eval_runtime': 6.6346, 'eval_samples_per_second': 345.761, 'eval_steps_per_second': 43.258, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 5502/25810 [08:17<28:32, 11.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3132, 'grad_norm': 3.479875326156616, 'learning_rate': 1.573808601317319e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6002/25810 [09:00<27:41, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3178, 'grad_norm': 4.397679328918457, 'learning_rate': 1.5350639287098025e-05, 'epoch': 2.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 6502/25810 [09:42<28:20, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2929, 'grad_norm': 2.8243234157562256, 'learning_rate': 1.4963192561022861e-05, 'epoch': 2.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 7002/25810 [10:24<28:42, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2813, 'grad_norm': 2.372600793838501, 'learning_rate': 1.4575745834947696e-05, 'epoch': 2.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7502/25810 [11:06<25:35, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2637, 'grad_norm': 2.3474748134613037, 'learning_rate': 1.4188299108872531e-05, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 30%|███       | 7743/25810 [11:33<26:28, 11.38it/s]c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 30%|███       | 7744/25810 [11:33<5:31:19,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22030100226402283, 'eval_accuracy': 0.9504830516915109, 'eval_precision': 0.5842364532019705, 'eval_recall': 0.6885341074020319, 'eval_f1': 0.632111925383078, 'eval_runtime': 6.6738, 'eval_samples_per_second': 343.734, 'eval_steps_per_second': 43.004, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 8002/25810 [11:55<24:32, 12.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2518, 'grad_norm': 2.163127899169922, 'learning_rate': 1.3800852382797368e-05, 'epoch': 3.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8502/25810 [12:37<23:41, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2453, 'grad_norm': 2.2425992488861084, 'learning_rate': 1.3413405656722203e-05, 'epoch': 3.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 9002/25810 [13:21<23:17, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2457, 'grad_norm': 4.6998724937438965, 'learning_rate': 1.3025958930647038e-05, 'epoch': 3.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 9502/25810 [14:04<24:05, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2392, 'grad_norm': 1.7923890352249146, 'learning_rate': 1.2638512204571873e-05, 'epoch': 3.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 10002/25810 [14:46<21:38, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2286, 'grad_norm': 2.4995405673980713, 'learning_rate': 1.225106547849671e-05, 'epoch': 3.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 40%|████      | 10324/25810 [15:21<22:04, 11.69it/s]Checkpoint destination directory ./ner_output\\checkpoint-10324 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18404588103294373, 'eval_accuracy': 0.9564423491915939, 'eval_precision': 0.6169483223120255, 'eval_recall': 0.7312046444121916, 'eval_f1': 0.6692348565356004, 'eval_runtime': 6.974, 'eval_samples_per_second': 328.936, 'eval_steps_per_second': 41.153, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 10502/25810 [15:36<20:39, 12.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2183, 'grad_norm': 2.9204883575439453, 'learning_rate': 1.1863618752421544e-05, 'epoch': 4.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 11002/25810 [16:19<21:22, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2229, 'grad_norm': 3.029761552810669, 'learning_rate': 1.147617202634638e-05, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 11502/25810 [17:02<20:01, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2093, 'grad_norm': 1.8175920248031616, 'learning_rate': 1.1088725300271212e-05, 'epoch': 4.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 12002/25810 [17:44<20:47, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2083, 'grad_norm': 5.703102111816406, 'learning_rate': 1.0701278574196047e-05, 'epoch': 4.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12502/25810 [18:27<19:25, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1925, 'grad_norm': 3.301931142807007, 'learning_rate': 1.0313831848120884e-05, 'epoch': 4.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 50%|█████     | 12905/25810 [19:09<18:44, 11.47it/s]Checkpoint destination directory ./ner_output\\checkpoint-12905 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 50%|█████     | 12906/25810 [19:09<3:56:30,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1632247120141983, 'eval_accuracy': 0.9605922778128216, 'eval_precision': 0.6405472636815921, 'eval_recall': 0.7474600870827286, 'eval_f1': 0.6898861352980576, 'eval_runtime': 6.6912, 'eval_samples_per_second': 342.837, 'eval_steps_per_second': 42.892, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 13002/25810 [19:17<18:36, 11.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1881, 'grad_norm': 3.8463759422302246, 'learning_rate': 9.926385122045719e-06, 'epoch': 5.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13500/25810 [20:00<16:44, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2002, 'grad_norm': 2.434706687927246, 'learning_rate': 9.538938395970556e-06, 'epoch': 5.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 14002/25810 [20:42<16:05, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1814, 'grad_norm': 2.885169506072998, 'learning_rate': 9.15149166989539e-06, 'epoch': 5.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14502/25810 [21:25<15:46, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1826, 'grad_norm': 3.2642149925231934, 'learning_rate': 8.764044943820226e-06, 'epoch': 5.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 15002/25810 [22:08<15:28, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1787, 'grad_norm': 2.0341858863830566, 'learning_rate': 8.37659821774506e-06, 'epoch': 5.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 60%|██████    | 15486/25810 [22:56<14:07, 12.18it/s]c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14847137033939362, 'eval_accuracy': 0.9635636267056207, 'eval_precision': 0.6562578066450162, 'eval_recall': 0.7625544267053701, 'eval_f1': 0.7054242749731472, 'eval_runtime': 7.0798, 'eval_samples_per_second': 324.022, 'eval_steps_per_second': 40.538, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15500/25810 [22:57<37:37,  4.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1744, 'grad_norm': 1.4434393644332886, 'learning_rate': 7.989151491669897e-06, 'epoch': 6.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 16002/25810 [23:41<14:10, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1737, 'grad_norm': 3.1197919845581055, 'learning_rate': 7.601704765594732e-06, 'epoch': 6.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16502/25810 [24:25<13:13, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1791, 'grad_norm': 2.9168827533721924, 'learning_rate': 7.214258039519567e-06, 'epoch': 6.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 17002/25810 [25:08<12:41, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1672, 'grad_norm': 2.3247663974761963, 'learning_rate': 6.826811313444401e-06, 'epoch': 6.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17502/25810 [25:51<12:03, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1608, 'grad_norm': 2.9380857944488525, 'learning_rate': 6.439364587369237e-06, 'epoch': 6.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 18002/25810 [26:34<11:07, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1675, 'grad_norm': 3.9264659881591797, 'learning_rate': 6.051917861294072e-06, 'epoch': 6.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 70%|███████   | 18067/25810 [26:47<11:08, 11.59it/s]c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 70%|███████   | 18068/25810 [26:47<2:25:14,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13884370028972626, 'eval_accuracy': 0.9659705853059327, 'eval_precision': 0.6697569531445753, 'eval_recall': 0.7759071117561683, 'eval_f1': 0.7189349112426036, 'eval_runtime': 6.8568, 'eval_samples_per_second': 334.559, 'eval_steps_per_second': 41.856, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18502/25810 [27:24<10:14, 11.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1673, 'grad_norm': 1.7235767841339111, 'learning_rate': 5.664471135218908e-06, 'epoch': 7.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 19002/25810 [28:08<09:52, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1715, 'grad_norm': 2.867598295211792, 'learning_rate': 5.277024409143743e-06, 'epoch': 7.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19502/25810 [28:51<09:29, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1623, 'grad_norm': 2.438126564025879, 'learning_rate': 4.8895776830685785e-06, 'epoch': 7.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 20002/25810 [29:35<08:18, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1553, 'grad_norm': 3.1397852897644043, 'learning_rate': 4.5021309569934135e-06, 'epoch': 7.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 20502/25810 [30:18<07:43, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1516, 'grad_norm': 5.04334831237793, 'learning_rate': 4.1146842309182484e-06, 'epoch': 7.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 80%|████████  | 20648/25810 [30:37<06:54, 12.46it/s]c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13281629979610443, 'eval_accuracy': 0.9671657647488463, 'eval_precision': 0.6766181635725038, 'eval_recall': 0.7828737300435413, 'eval_f1': 0.7258780783205492, 'eval_runtime': 6.7716, 'eval_samples_per_second': 338.769, 'eval_steps_per_second': 42.383, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 21002/25810 [31:07<06:48, 11.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.157, 'grad_norm': 2.00166654586792, 'learning_rate': 3.7272375048430843e-06, 'epoch': 8.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 21502/25810 [31:51<06:15, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.155, 'grad_norm': 1.28708815574646, 'learning_rate': 3.3397907787679196e-06, 'epoch': 8.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 22002/25810 [32:35<05:20, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.157, 'grad_norm': 1.8121753931045532, 'learning_rate': 2.952344052692755e-06, 'epoch': 8.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 22502/25810 [33:18<04:47, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.152, 'grad_norm': 3.1360034942626953, 'learning_rate': 2.5648973266175904e-06, 'epoch': 8.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 23002/25810 [34:02<04:12, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1524, 'grad_norm': 0.817374050617218, 'learning_rate': 2.1774506005424258e-06, 'epoch': 8.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 90%|█████████ | 23229/25810 [34:28<03:48, 11.28it/s]c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 90%|█████████ | 23230/25810 [34:28<48:06,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12933914363384247, 'eval_accuracy': 0.967979150758607, 'eval_precision': 0.6824358329139406, 'eval_recall': 0.7872278664731495, 'eval_f1': 0.7310958350181965, 'eval_runtime': 6.8163, 'eval_samples_per_second': 336.545, 'eval_steps_per_second': 42.105, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 23501/25810 [34:52<03:15, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1569, 'grad_norm': 4.487970352172852, 'learning_rate': 1.790003874467261e-06, 'epoch': 9.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 24001/25810 [35:36<02:34, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1571, 'grad_norm': 1.1316906213760376, 'learning_rate': 1.4025571483920963e-06, 'epoch': 9.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 24501/25810 [36:19<01:55, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1484, 'grad_norm': 2.4904260635375977, 'learning_rate': 1.0151104223169315e-06, 'epoch': 9.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 25001/25810 [37:02<01:09, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1517, 'grad_norm': 2.22245717048645, 'learning_rate': 6.276636962417668e-07, 'epoch': 9.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 25501/25810 [37:46<00:25, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1517, 'grad_norm': 0.9262222051620483, 'learning_rate': 2.402169701666021e-07, 'epoch': 9.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 25810/25810 [38:20<00:00, 11.22it/s]\n",
      "c:\\Users\\Rajveer Mathur\\Desktop\\NER-BERT-finetuning\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1283436119556427, 'eval_accuracy': 0.9682115467613958, 'eval_precision': 0.6833626982129374, 'eval_recall': 0.7880986937590712, 'eval_f1': 0.732003235373416, 'eval_runtime': 6.8195, 'eval_samples_per_second': 336.39, 'eval_steps_per_second': 42.085, 'epoch': 10.0}\n",
      "{'train_runtime': 2300.1759, 'train_samples_per_second': 89.75, 'train_steps_per_second': 11.221, 'train_loss': 0.30106123488617237, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:06<00:00, 42.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Evaluation Metrics:\n",
      "eval_loss: 0.1283\n",
      "eval_accuracy: 0.9682\n",
      "eval_precision: 0.6834\n",
      "eval_recall: 0.7881\n",
      "eval_f1: 0.7320\n",
      "eval_runtime: 6.7172\n",
      "eval_samples_per_second: 341.5090\n",
      "eval_steps_per_second: 42.7260\n",
      "epoch: 10.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Trainer start\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = trainer.evaluate()\n",
    "print(\"📈 Evaluation Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./final_ner_model_bert-tiny\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./final_ner_model_bert-tiny\\\\tokenizer_config.json',\n",
       " './final_ner_model_bert-tiny\\\\special_tokens_map.json',\n",
       " './final_ner_model_bert-tiny\\\\vocab.txt',\n",
       " './final_ner_model_bert-tiny\\\\added_tokens.json',\n",
       " './final_ner_model_bert-tiny\\\\tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Saving\n",
    "save_directory = f\"./final_ner_model_{model_checkpoint.split('/')[-1]}\"\n",
    "print(f\"Saving model to {save_directory}\")\n",
    "\n",
    "trainer.save_model(f\"./final_ner_model_{model_checkpoint.split('/')[-1]}\")\n",
    "tokenizer.save_pretrained(f\"./final_ner_model_{model_checkpoint.split('/')[-1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'FULLNAME', 'score': np.float32(0.94410837), 'word': 'dr. marvin rolfson', 'start': 0, 'end': 18}, {'entity_group': 'FULLNAME', 'score': np.float32(0.97039366), 'word': 'julius daugherty', 'start': 23, 'end': 39}, {'entity_group': 'NUMBER', 'score': np.float32(0.33254895), 'word': '91 - 80099', 'start': 91, 'end': 99}, {'entity_group': 'STREETADDRESS', 'score': np.float32(0.20343716), 'word': '##23', 'start': 100, 'end': 102}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipeline = pipeline(\"ner\", model=f\"./final_ner_model_{model_checkpoint.split('/')[-1]}\", tokenizer=f\"./final_ner_model_{model_checkpoint.split('/')[-1]}\", aggregation_strategy=\"simple\")\n",
    "\n",
    "text = \"Dr. Marvin Rolfson and Julius Daugherty attended the arbitration. Their contact number is +91-8009992328\"\n",
    "print(ner_pipeline(text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
